{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a30a3aa8-02c7-4e79-b78f-fcd5e9339b27",
   "metadata": {},
   "source": [
    "# Bankrupcy Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770c24af-48cb-4469-acde-b6b12a1d3164",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ad83b8-e5b6-48b0-b9ae-ac1d06a5fa7f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-06T14:41:46.702456Z",
     "start_time": "2025-10-06T14:41:45.854540Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c060b3a-0c31-472f-9606-27b67f088354",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c8a277-b459-4b24-80c6-491913e4c4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"company_info.xlsx\"\n",
    "folder = \"./\"\n",
    "file_path = os.path.join(folder, filename)\n",
    "df1 = pd.read_excel(file_path, engine=\"openpyxl\", sheet_name=0)\n",
    "df2 = pd.read_excel(file_path, engine=\"openpyxl\", sheet_name=1)\n",
    "\n",
    "df = pd.concat([df1, df2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ffdaaa-1d95-4bea-99a9-ff19a771b73f",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb901dd6-9afe-4057-af1e-25c14b246233",
   "metadata": {},
   "source": [
    "Typical data exploration tasks:\n",
    "- dataset size (samples, features)\n",
    "- variables without values\n",
    "- description, column statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf963c47-af5a-46fc-9b6d-655af49f630b",
   "metadata": {},
   "source": [
    "Data size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e98225-580c-4a4d-afef-9fa3684921c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape:{}\".format(df.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c526ae-cb39-4758-a685-3639fdaef2f2",
   "metadata": {},
   "source": [
    "Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cedea3-dff1-4c11-bd53-a9d5e39e9fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"DESCRIBE:{}\".format(df.describe(include=\"all\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713e83b8-0f3c-4306-ac88-530e78238ff5",
   "metadata": {},
   "source": [
    "Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb71276-c0e6-4f6d-9a84-00661dc2277b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"INFO:{}\".format(df.info))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b463359-8d26-4cc8-83ea-b41060166a39",
   "metadata": {},
   "source": [
    "Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8533969-ba83-4af2-9ae7-5363e3c935bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Columns:{}\".format(df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f7af6f-30a2-45d7-b487-5d6dfa5cc2c1",
   "metadata": {},
   "source": [
    "HEAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b223cdc-14e4-49be-b8dd-e6fffc71c552",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"HEAD:{}\".format(df.head()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fd689e-5873-481e-893e-d20369a43b37",
   "metadata": {},
   "source": [
    "Data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e009bf-3780-4e8d-8af7-0f4e88538674",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"DTYPES:{}\".format(df.dtypes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88be839e-bc34-490e-8f3d-fd34b0e2ab6e",
   "metadata": {},
   "source": [
    "## Data cleanup "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be96b1a-840d-4538-9202-6f18f29a3eb9",
   "metadata": {},
   "source": [
    "Typical columns to drop:\n",
    "- semanticaly meaningless columns\n",
    "- columns with little data\n",
    "- columns with very low variance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c22d8d-7b9c-41b0-bfb3-93a3d1579712",
   "metadata": {},
   "source": [
    "Drop useless columns and columns with little data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04709fbd-496a-47b5-8923-1e1270d1b702",
   "metadata": {},
   "outputs": [],
   "source": [
    "useless_columns = [\"Unnamed: 0\",\n",
    "                   \"NACE Rev. 2, core code (4 digits)\"]\n",
    "\n",
    "bad_columns_to_drop = [\"X2=Equity/liabilities\",\n",
    "                       \"X7=Current Liabilities /Inventory\",\n",
    "                       \"X26=Financing Charge / Sales\"]\n",
    "\n",
    "df.drop(columns=useless_columns, inplace=True)\n",
    "df.drop(columns=bad_columns_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0844a0-a79a-459c-b927-39281b28706a",
   "metadata": {},
   "source": [
    "Convert country names to numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f903442c-d84d-4659-a868-8f6f9b95f635",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace(\"ES\", 0, inplace=True)\n",
    "df.replace(\"PT\", 1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efc9212-34cf-40d4-a555-8f691fb71506",
   "metadata": {},
   "source": [
    "Check what data looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d193928-fe07-4f16-88ef-64cfb1494728",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"DESCRIBE:{}\".format(df.describe(include=\"all\")))\n",
    "print(\"DTYPES:{}\".format(df.dtypes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10339af8-d259-4db8-9090-8668f3581b29",
   "metadata": {},
   "source": [
    "Drop lines with nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f206389-1506-423a-b74a-21e8089c8ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(axis=0, inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb22bc4-da33-45aa-9a60-0f0e32cb2657",
   "metadata": {},
   "source": [
    "Convert country code column to int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239b4b97-881a-4e72-b290-51e0b8afd991",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df.columns:\n",
    "    if column == \"Country ISO code\":\n",
    "        df[column] = df[column].astype(\"int\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2ff753-5bde-46f0-8a35-3ad2e3df78b2",
   "metadata": {},
   "source": [
    "Check what data looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46b262e-8431-46b2-8e43-d5385ee54f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"DESCRIBE:{}\".format(df.describe(include=\"all\")))\n",
    "print(\"DTYPES:{}\".format(df.dtypes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8d0236-570e-44fa-a545-a3a935a82dae",
   "metadata": {},
   "source": [
    "Separate features from class and convert to numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d632713-4c17-44ef-a769-ff1398c972de",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.array(df[\"Situation\"])\n",
    "df.drop(\"Situation\", axis=1, inplace=True)\n",
    "X = np.array(df, dtype=\"float64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104f75ef-799f-4273-b763-3aff7b59140d",
   "metadata": {},
   "source": [
    "# Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0c11b6-094c-4aa4-956c-003ea9e21125",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, stratify=Y, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b5e6f2-1013-42f7-a0a5-143c5d56bb2e",
   "metadata": {},
   "source": [
    "# Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b488aa33-c4e2-466e-927b-8f9ba807d967",
   "metadata": {},
   "outputs": [],
   "source": [
    "means = np.zeros((len(df.columns)))\n",
    "stds = np.zeros((len(df.columns)))\n",
    "\n",
    "columns_without_normalization = [\"Country ISO code\"]\n",
    "\n",
    "for col_index in range(X_train.shape[1]):\n",
    "    col_name = df.columns[col_index]\n",
    "    if col_name in columns_without_normalization:\n",
    "        print(\"Not normalizing\", col_name)\n",
    "    else:\n",
    "        print(\"Normalizing\", col_name)\n",
    "        col_mean = np.mean(X_train[:, col_index])\n",
    "        means[col_index] = col_mean\n",
    "        col_std = np.std(X_train[:, col_index])\n",
    "        stds[col_index] = col_std\n",
    "        X_train[:, col_index] = (X_train[:, col_index] - col_mean) / col_std\n",
    "        X_test[:, col_index] = (X_test[:, col_index] - col_mean) / col_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740edff6-b69e-4e14-b4c0-5f62c5497c56",
   "metadata": {},
   "source": [
    "# Train Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896a0de4-81cc-43fb-8721-5332381f9bbd",
   "metadata": {},
   "source": [
    "List models to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548dfbd3-720f-41de-bd0d-3a07b6cb6aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"LinearSVC\", \"SVC\", \"KNN\", \"LogisticRegression\", \"DecisionTree\", \"RandomForest\", \"ExtremeForest\", \"AdaBoost\", \"MLP\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a809c02e-95a8-4c49-b71e-27ba466f8e8c",
   "metadata": {},
   "source": [
    "Create data structures for results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60dd5b2-11aa-47a4-b38a-2f7d16ce8f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = 10  # number of times to run each model\n",
    "accuracies = np.zeros((len(models), runs))\n",
    "C1_precisions = np.zeros((len(models), runs))\n",
    "C1_recalls = np.zeros((len(models), runs))\n",
    "C1_fscores = np.zeros((len(models), runs))\n",
    "C0_precisions = np.zeros((len(models), runs))\n",
    "C0_recalls = np.zeros((len(models), runs))\n",
    "C0_fscores = np.zeros((len(models), runs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd0430d-c161-4dbd-b9a8-4cb160ce87d9",
   "metadata": {},
   "source": [
    "Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58d496e-6ab7-41ad-a8f9-e61899a247ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.RandomState(1)\n",
    "\n",
    "for model_to_try_i in range(len(models)):\n",
    "    model_to_try = models[model_to_try_i]\n",
    "    print(\"Model to try: \", model_to_try)\n",
    "\n",
    "    for try_i in range(runs):\n",
    "        if model_to_try == \"LinearSVC\":\n",
    "            model = LinearSVC(C=1.0,\n",
    "                              class_weight=None,\n",
    "                              max_iter=1000000,\n",
    "                              dual=True,\n",
    "                              loss='squared_hinge'\n",
    "                              )\n",
    "        elif model_to_try == \"SVC\":\n",
    "            model = SVC(C=1.0,\n",
    "                        kernel='rbf',\n",
    "                        class_weight=None,\n",
    "                        gamma='scale'\n",
    "                        )\n",
    "        elif model_to_try == \"KNN\":\n",
    "            model = KNeighborsClassifier(n_neighbors=5,\n",
    "                                         algorithm='auto',\n",
    "                                         weights='uniform',\n",
    "                                         metric='minkowski'\n",
    "                                         )\n",
    "        elif model_to_try == \"LogisticRegression\":\n",
    "            model = LogisticRegression(\n",
    "                                       solver='lbfgs',\n",
    "                                       class_weight=None,\n",
    "                                       penalty='l2',\n",
    "                                       max_iter=100000)\n",
    "        elif model_to_try == \"DecisionTree\":\n",
    "            model = DecisionTreeClassifier(max_depth=None,\n",
    "                                           max_features=None,\n",
    "                                           criterion='gini',\n",
    "                                           class_weight=None\n",
    "                                           )\n",
    "        elif model_to_try == \"RandomForest\":\n",
    "            model = RandomForestClassifier(n_estimators=1000,\n",
    "                                           criterion='gini',\n",
    "                                           max_features='sqrt',\n",
    "                                           class_weight=None                                           \n",
    "                                           )\n",
    "        elif model_to_try == \"ExtremeForest\":\n",
    "            model = ExtraTreesClassifier(n_estimators=1000,\n",
    "                                         criterion='gini',\n",
    "                                         max_features='sqrt',\n",
    "                                         class_weight=None                                         \n",
    "                                         )\n",
    "        elif model_to_try == \"AdaBoost\":\n",
    "            model = AdaBoostClassifier(n_estimators=100,\n",
    "                                       learning_rate=1.0\n",
    "                                       )\n",
    "        elif model_to_try == \"MLP\":\n",
    "            model = MLPClassifier(hidden_layer_sizes=(100, 100),\n",
    "                                  activation='relu',\n",
    "                                  solver='adam',\n",
    "                                  learning_rate='constant',\n",
    "                                  max_iter=1000\n",
    "                                  )\n",
    "\n",
    "        print(\"Model:\", model, \"try \", str(try_i), \"/\", str(runs))\n",
    "\n",
    "        # train model\n",
    "        history = model.fit(X_train, y_train)\n",
    "        # print(\"History:\")\n",
    "        # print(history)\n",
    "\n",
    "        # test model\n",
    "        y_test_predict = model.predict(X_test)\n",
    "\n",
    "        # evaluate model\n",
    "        # Evaluate the default option\n",
    "        # jaccard = metrics.jaccard_score(y_test, y_test_predict)\n",
    "        # print(\"Jaccard:\", jaccard)\n",
    "        accuracy = metrics.accuracy_score(y_test, y_test_predict)\n",
    "        prfs = metrics.precision_recall_fscore_support(y_test, y_test_predict)\n",
    "        confusion_matrix = metrics.confusion_matrix(y_test, y_test_predict, labels=[0, 1])\n",
    "        # print(\"Train set Accuracy:\", metrics.accuracy_score(y_train, y_train_predict))\n",
    "        print(\"Test set Accuracy:\", accuracy)\n",
    "        print(\"Test set Class 0 Precision, Recall, F-score:\", prfs[0][0], prfs[1][0], prfs[2][0])\n",
    "        print(\"Test set Class 1 Precision, Recall, F-score:\", prfs[0][1], prfs[1][1], prfs[2][1])\n",
    "        print(\"Confusion matrix:\")\n",
    "        print(confusion_matrix)\n",
    "\n",
    "        print(\"Classification Report:\")\n",
    "        print(metrics.classification_report(y_test, y_test_predict))\n",
    "\n",
    "        accuracies[model_to_try_i, try_i] = accuracy\n",
    "        C0_precisions[model_to_try_i, try_i] = prfs[0][0]\n",
    "        C0_recalls[model_to_try_i, try_i] = prfs[1][0]\n",
    "        C0_fscores[model_to_try_i, try_i] = prfs[2][0]\n",
    "        C1_precisions[model_to_try_i, try_i] = prfs[0][1]\n",
    "        C1_recalls[model_to_try_i, try_i] = prfs[1][1]\n",
    "        C1_fscores[model_to_try_i, try_i] = prfs[2][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43828742-c55c-4d58-b1cb-474b8a67375b",
   "metadata": {},
   "source": [
    "Save results to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c57441-b77a-455d-abfb-a16b3682e257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model results\n",
    "results_folder = \"results\"\n",
    "if not os.path.exists(results_folder):\n",
    "    os.makedirs(results_folder)\n",
    "\n",
    "if os.path.exists(os.path.join(results_folder, \"accuracies.npy\")):\n",
    "    os.remove(os.path.join(results_folder, \"accuracies.npy\"))\n",
    "np.save(os.path.join(results_folder, \"accuracies.npy\"), accuracies)\n",
    "\n",
    "if os.path.exists(os.path.join(results_folder, \"C1_precisions.npy\")):\n",
    "    os.remove(os.path.join(results_folder, \"C1_precisions.npy\"))\n",
    "np.save(os.path.join(results_folder, \"C1_precisions.npy\"), C1_precisions)\n",
    "\n",
    "if os.path.exists(os.path.join(results_folder, \"C1_recalls.npy\")):\n",
    "    os.remove(os.path.join(results_folder, \"C1_recalls.npy\"))\n",
    "np.save(os.path.join(results_folder, \"C1_recalls.npy\"), C1_recalls)\n",
    "\n",
    "if os.path.exists(os.path.join(results_folder, \"C1_fscores.npy\")):\n",
    "    os.remove(os.path.join(results_folder, \"C1_fscores.npy\"))\n",
    "np.save(os.path.join(results_folder, \"C1_fscores.npy\"), C1_fscores)\n",
    "\n",
    "if os.path.exists(os.path.join(results_folder, \"C0_precisions.npy\")):\n",
    "    os.remove(os.path.join(results_folder, \"C0_precisions.npy\"))\n",
    "np.save(os.path.join(results_folder, \"C0_precisions.npy\"), C0_precisions)\n",
    "\n",
    "if os.path.exists(os.path.join(results_folder, \"C0_recalls.npy\")):\n",
    "    os.remove(os.path.join(results_folder, \"C0_recalls.npy\"))\n",
    "np.save(os.path.join(results_folder, \"C0_recalls.npy\"), C0_recalls)\n",
    "\n",
    "if os.path.exists(os.path.join(results_folder, \"C0_fscores.npy\")):\n",
    "    os.remove(os.path.join(results_folder, \"C0_fscores.npy\"))\n",
    "np.save(os.path.join(results_folder, \"C0_fscores.npy\"), C0_fscores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e878f4e42389c81b",
   "metadata": {},
   "source": [
    "Load results files\n",
    "\n",
    "Compute means and std deviations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa0bb77514bf2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = np.load(os.path.join(results_folder, \"accuracies.npy\"))\n",
    "C0_fscores = np.load(os.path.join(results_folder, \"C0_fscores.npy\"))\n",
    "C0_precisions = np.load(os.path.join(results_folder, \"C0_precisions.npy\"))\n",
    "C0_recalls = np.load(os.path.join(results_folder, \"C0_recalls.npy\"))\n",
    "C1_fscores = np.load(os.path.join(results_folder, \"C1_fscores.npy\"))\n",
    "C1_precisions = np.load(os.path.join(results_folder, \"C1_precisions.npy\"))\n",
    "C1_recalls = np.load(os.path.join(results_folder, \"C1_recalls.npy\"))\n",
    "\n",
    "accuracies_mean = np.zeros((len(models), ))\n",
    "accuracies_std = np.zeros((len(models), ))\n",
    "C0_fscores_mean = np.zeros((len(models), ))\n",
    "C0_fscores_std = np.zeros((len(models), ))\n",
    "C0_precisions_mean = np.zeros((len(models), ))\n",
    "C0_precisions_std = np.zeros((len(models), ))\n",
    "C0_recalls_mean = np.zeros((len(models), ))\n",
    "C0_recalls_std = np.zeros((len(models), ))\n",
    "\n",
    "C1_fscores_mean = np.zeros((len(models), ))\n",
    "C1_fscores_std = np.zeros((len(models), ))\n",
    "C1_precisions_mean = np.zeros((len(models), ))\n",
    "C1_precisions_std = np.zeros((len(models), ))\n",
    "C1_recalls_mean = np.zeros((len(models), ))\n",
    "C1_recalls_std = np.zeros((len(models), ))\n",
    "\n",
    "for model_to_try_i in range(len(models)):\n",
    "    C0_precisions_mean[model_to_try_i] = C0_precisions[model_to_try_i, :].mean(axis=0)\n",
    "    C0_precisions_std[model_to_try_i] = C0_precisions[model_to_try_i, :].std(axis=0)\n",
    "    C0_recalls_mean[model_to_try_i] = C0_recalls[model_to_try_i, :].mean(axis=0)\n",
    "    C0_recalls_std[model_to_try_i] = C0_recalls[model_to_try_i, :].std(axis=0)\n",
    "    C0_fscores_mean[model_to_try_i] = C0_fscores[model_to_try_i, :].mean(axis=0)\n",
    "    C0_fscores_std[model_to_try_i] = C0_fscores[model_to_try_i, :].std(axis=0)\n",
    "    accuracies_mean[model_to_try_i] = accuracies[model_to_try_i, :].mean(axis=0)\n",
    "    accuracies_std[model_to_try_i] = accuracies[model_to_try_i, :].std(axis=0)\n",
    "    C1_precisions_mean[model_to_try_i] = C1_precisions[model_to_try_i, :].mean(axis=0)\n",
    "    C1_precisions_std[model_to_try_i] = C1_precisions[model_to_try_i, :].std(axis=0)\n",
    "    C1_recalls_mean[model_to_try_i] = C1_recalls[model_to_try_i, :].mean(axis=0)\n",
    "    C1_recalls_std[model_to_try_i] = C1_recalls[model_to_try_i, :].std(axis=0)\n",
    "    C1_fscores_mean[model_to_try_i] = C1_fscores[model_to_try_i, :].mean(axis=0)\n",
    "    C1_fscores_std[model_to_try_i] = C1_fscores[model_to_try_i, :].std(axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502daa09-11dc-439c-8d32-b83d26d3d036",
   "metadata": {},
   "source": [
    "Plot accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76829a77-db27-4160-8054-fdfd71840bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = [\"LinearSVC\", \"SVC\", \"KNN\", \"LogisticRegression\", \"DecisionTree\", \"RandomForest\", \"ExtremeForest\", \"AdaBoost\", \"MLP\"]\n",
    "models_charts = [\"L-SVM\", \"K-SVM\", \"KNN\", \"LR\", \"DT\", \"RF\", \"ERF\", \"AdaBoost\", \"MLP\"]\n",
    "\n",
    "print(\"Accuracy\")\n",
    "accuracies_t = np.transpose(accuracies)\n",
    "plt.boxplot(accuracies_t)\n",
    "axes = plt.gca()\n",
    "axes.set_ylim([0.8, 1.0])\n",
    "axes.set_xticklabels(models_charts)\n",
    "plt.title(('Model Accuracies'))\n",
    "#plt.legend(models)\n",
    "plt.ylabel('Accuracy ')\n",
    "plt.xlabel('Model')\n",
    "plt.tight_layout()\n",
    "plt.savefig(fname=results_folder+\"/accuracy.png\")\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e62158-63d5-4d80-9f48-87999ac751ae",
   "metadata": {},
   "source": [
    "Plot Precision-Recall-FScore C0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb2782e-4dfc-48aa-a1ab-5d9c6a189e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Precision C0\")\n",
    "precisions_t=np.transpose(C0_precisions)\n",
    "plt.boxplot(precisions_t)\n",
    "axes = plt.gca()\n",
    "axes.set_ylim([0.5, 1.0])\n",
    "axes.set_xticklabels(models_charts)\n",
    "plt.title(('Model Precisions C0'))\n",
    "#plt.legend(models)\n",
    "plt.ylabel('Precision C0')\n",
    "plt.xlabel('Method')\n",
    "plt.tight_layout()\n",
    "plt.savefig(fname=results_folder+\"/C0_precision.png\")\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "print(\"Recall C0\")\n",
    "recalls_t = np.transpose(C0_recalls)\n",
    "plt.boxplot(recalls_t)\n",
    "axes = plt.gca()\n",
    "axes.set_ylim([0, 1.0])\n",
    "axes.set_xticklabels(models_charts)\n",
    "plt.title(('Model Recalls C0'))\n",
    "#plt.legend(models)\n",
    "plt.ylabel('Recall')\n",
    "plt.xlabel('Model')\n",
    "plt.tight_layout()\n",
    "plt.savefig(fname=results_folder+\"/C0_recall.png\")\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "print(\"F-score C0\")\n",
    "fscores_t=np.transpose(C0_fscores)\n",
    "plt.boxplot(fscores_t)\n",
    "axes = plt.gca()\n",
    "axes.set_ylim([0.0, 1.0])\n",
    "axes.set_xticklabels(models_charts)\n",
    "plt.title(('Model F-scores C0'))\n",
    "#plt.legend(methods)\n",
    "plt.ylabel('F-score')\n",
    "plt.xlabel('Model')\n",
    "plt.tight_layout()\n",
    "plt.savefig(fname=results_folder+\"/C0_f-score.png\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acb96c7-db08-45d9-8482-99757616cb07",
   "metadata": {},
   "source": [
    "Plot Precision-Recall-FScore C1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8549267a-f518-4169-baec-147d486a3397",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Precision C1\")\n",
    "precisions_t=np.transpose(C1_precisions)\n",
    "plt.boxplot(precisions_t)\n",
    "axes = plt.gca()\n",
    "axes.set_ylim([0.85, 1.0])\n",
    "axes.set_xticklabels(models_charts)\n",
    "plt.title(('Model Precisions C1'))\n",
    "#plt.legend(models)\n",
    "plt.ylabel('Precision C1')\n",
    "plt.xlabel('Method')\n",
    "plt.tight_layout()\n",
    "plt.savefig(fname=results_folder+\"/C1_precision.png\")\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "print(\"Recall C1\")\n",
    "recalls_t = np.transpose(C1_recalls)\n",
    "plt.boxplot(recalls_t)\n",
    "axes = plt.gca()\n",
    "axes.set_ylim([0.85, 1.0])\n",
    "axes.set_xticklabels(models_charts)\n",
    "plt.title(('Model Recalls C1'))\n",
    "#plt.legend(models)\n",
    "plt.ylabel('Recall')\n",
    "plt.xlabel('Model')\n",
    "plt.tight_layout()\n",
    "plt.savefig(fname=results_folder+\"/C1_recall.png\")\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "print(\"F-score C1\")\n",
    "fscores_t=np.transpose(C1_fscores)\n",
    "plt.boxplot(fscores_t)\n",
    "axes = plt.gca()\n",
    "axes.set_ylim([0.85, 1.0])\n",
    "axes.set_xticklabels(models_charts)\n",
    "plt.title(('Model F-scores C1'))\n",
    "#plt.legend(methods)\n",
    "plt.ylabel('F-score')\n",
    "plt.xlabel('Model')\n",
    "plt.tight_layout()\n",
    "plt.savefig(fname=results_folder+\"/C1_f-score.png\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5151c84c-f7ce-4ad5-9333-c5eef5eeb82c",
   "metadata": {},
   "source": [
    "Print table in LaTex format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e538dfd4-bd06-452e-81e7-85be0b885a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model \\tAccuracy \\tPrecision C0 \\tRecall C0 \\tF-score C0 \\tPrecision C1 \\tRecall C1 \\tF-score C1\")\n",
    "for model_to_try_i in range(len(models)):\n",
    "    model_to_try = models[model_to_try_i]\n",
    "    print(\"{}\\t{:.1f}%\\t+-{:.1f}%\\t{:.1f}%\\t+-{:.1f}%\\t{:.1f}%\\t+-{:.1f}%\\t{:.1f}%\\t+-{:.1f}%\\t{:.1f}%\\t+-{:.1f}%\\t{:.1f}%\\t+-{:.1f}%\\t{:.1f}%\\t+-{:.1f}%\".format(\n",
    "        model_to_try,\n",
    "        accuracies_mean[model_to_try_i] * 100, accuracies_std[model_to_try_i] * 100,\n",
    "        C0_precisions_mean[model_to_try_i] * 100, C0_precisions_std[model_to_try_i] * 100,\n",
    "        C0_recalls_mean[model_to_try_i] * 100, C0_recalls_std[model_to_try_i] * 100,\n",
    "        C0_fscores_mean[model_to_try_i] * 100, C0_fscores_std[model_to_try_i] * 100,\n",
    "        C1_precisions_mean[model_to_try_i] * 100, C1_precisions_std[model_to_try_i] * 100,\n",
    "        C1_recalls_mean[model_to_try_i] * 100, C1_recalls_std[model_to_try_i] * 100,\n",
    "        C1_fscores_mean[model_to_try_i] * 100, C1_fscores_std[model_to_try_i] * 100,\n",
    "    ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
